<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://avatars.githubusercontent.com/u/105782835?s=400&u=04c0291bd1e06b01ccad1d53388ed4a8a8894a53&v=4"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="# 前言
MinHash LSH 是一种**高效的近似近邻搜索算法**，结合了 **MinHash 签名**和 **Locality-Sensitive Hashing（局部敏感哈希，LSH）** 两种技术，核心目标是在大规模高维数据集（如文本、图像特征、用户行为向量）中，快速找到**相似度高**的元素对，同时大幅降低计算和存储成本。">
<meta property="og:title" content="MinHash-LSH算法详解">
<meta property="og:description" content="# 前言
MinHash LSH 是一种**高效的近似近邻搜索算法**，结合了 **MinHash 签名**和 **Locality-Sensitive Hashing（局部敏感哈希，LSH）** 两种技术，核心目标是在大规模高维数据集（如文本、图像特征、用户行为向量）中，快速找到**相似度高**的元素对，同时大幅降低计算和存储成本。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://waibibab-cs.github.io/post/MinHash-LSH-suan-fa-xiang-jie.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/105782835?s=400&u=04c0291bd1e06b01ccad1d53388ed4a8a8894a53&v=4">
<title>MinHash-LSH算法详解</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>




<body>
    <div id="header">
<h1 class="postTitle">MinHash-LSH算法详解</h1>
<div class="title-right">
    <a href="https://waibibab-cs.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/waibibab-cs/waibibab-cs.github.io/issues/8" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h1>前言</h1>
<p>MinHash LSH 是一种<strong>高效的近似近邻搜索算法</strong>，结合了 <strong>MinHash 签名</strong>和 <strong>Locality-Sensitive Hashing（局部敏感哈希，LSH）</strong> 两种技术，核心目标是在大规模高维数据集（如文本、图像特征、用户行为向量）中，快速找到<strong>相似度高</strong>的元素对，同时大幅降低计算和存储成本。</p>
<p>参考资料：</p>
<ol>
<li><a href="https://blog.csdn.net/Vihagle/article/details/119319039?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5-119319039-blog-103281238.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5-119319039-blog-103281238.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;utm_relevant_index=10" rel="nofollow">RS推荐系统-LSH最近邻查找+MiniHash</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27712794839" rel="nofollow">LLM洗数据[MinHash LSH去重] 总结笔记</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/645577495" rel="nofollow">一文读懂局部敏感哈希（LSH）算法</a></li>
<li><a href="https://yinyayun.github.io/post/lsh/" rel="nofollow">Min-Hash &amp; LSH</a></li>
<li><a href="https://zilliz.com.cn/blog/Milvus2.6-launches-Minhash-LSH-for-low-cost-deduplication" rel="nofollow">Milvus week | 官宣：Milvus2.6发布MinHash LSH ，低成本去重百亿文档，加速大模型训练</a></li>
</ol>
<h1>算法过程介绍</h1>
<h2>算法总览</h2>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218145412.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218145412.png" alt="image.png" style="max-width: 100%;"></a><br>
算法的总体流程如上图所示，大体包含三个步骤：</p>
<ol>
<li>通过shingling和one-hot将一段文本转换为布尔向量（维度是n）</li>
<li>通过MinHash将上述布尔向量转换为哈希签名（维度是m，且m远小于n从而达到降维的目的）</li>
<li>通过LSH将每个哈希签名映射到不同的桶中</li>
</ol>
<h2>shingling+one-hot</h2>
<p><strong>Shingle（子串 / 词片）</strong>：指从文本或序列中截取的<strong>连续长度为 k</strong> 的子单元，子单元可以是<strong>字符</strong>或<strong>单词</strong></p>
<p><strong>k-shingling</strong>：对目标文本提取所有不重复的 k-shingle，构成一个<strong>集合</strong>（集合特性：元素无序、无重复），这个集合就是该文本的 <strong>k-shingle 特征表示</strong>。</p>
<p>比如有一段很长的文本，我们可以通过shingling得到这个文本的<strong>词表</strong>（或者成为词袋），如下所示（词表需要进行去重）<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218145814.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218145814.png" alt="image.png" style="max-width: 100%;"></a></p>
<p>创建词表之后，对于一段文本t，我们就可以通过对照词表，使用one-hot编码，将文本t转换为布尔向量v<br>
一个例子见下图，对于一段文本，我们将其shingling成集合shingle set后，对照词表vocab进行one-hot编码，由于shingle set中包含"ly"这个shingle，故对应于vocab的one-hot编码的第一个位置就为1，同理，shingle set中包含"ti"这个shingle，故对应于vocab的one-hot编码的第一个位置就为1，以此类推，我们就得到一个很长的01向量，向量维度就是词表中shingle的个数<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218150334.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218150334.png" alt="image.png" style="max-width: 100%;"></a></p>
<h2>Jaccard相似度</h2>
<p>如果我们量化两个文本t1和t2的相似度，就可以按照shingling+one-hot的方法，将文本先分别转换为两个布尔向量v1和v2，然后再求Jaccard相似度，其公式为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218150740.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218150740.png" alt="image.png" style="max-width: 100%;"></a><br>
直接用例子来说明，现在有四个文本，对应表格中的每一列，现在求前两个文本的相似度，使用上述公式，分子为2（同时为1的次数），分母为5，因此最终相似度为0.4<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218151230.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218151230.png" alt="image.png" style="max-width: 100%;"></a></p>
<h2>MinHash</h2>
<p>当词表中不重复的shingle过多时，上述得到的布尔向量的维度就会很大，在向量检索时，求不同向量间的Jaccard相似度开销就会变大。MinHash则可以通过将上述布尔向量转换为多个哈希签名来进行降维。<br>
假设有4个文本，每个文本原来的布尔向量维度是7，且我们想通过MinHash将这个7维降为3维，那么MinHash的步骤如下：（下图展现的是原始的布尔向量矩阵，每一列代表一个文本）<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218152821.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218152821.png" alt="image.png" style="max-width: 100%;"></a><br>
step1.随机生成3个1-7的全排列<br>
例如：<br>
h1：3 1 6 2 7 4 5<br>
h2：3 2 4 1 6 5 7<br>
h3：......<br>
step2.分别将原来的布尔向量矩阵的行依次按照每个全排列进行重排，例如，对于h1和h2重排后因此得到下面两个矩阵mh1和mh2<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218153853.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218153853.png" alt="image.png" style="max-width: 100%;"></a><br>
step3.每个矩阵通过取出每列首个为1的行数就可以生成一行哈希签名，以mh1为例，第1列首个1的行数为2，第2列首个1的行数为1，第3列为2，第4列为1，所以最终可以得到（2121）这个hash后的数值<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218153956.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218153956.png" alt="image.png" style="max-width: 100%;"></a><br>
重复step3，生成m个hash后的数值，从而得到下面的哈希签名矩阵<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154056.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154056.png" alt="image.png" style="max-width: 100%;"></a><br>
得到这个有什么用呢，发现如果此时我们去比较不同哈希签名间的jaccard相似度只需要处理3个维度，而不是原来布尔向量的7个维度，但哈希签名的jaccard相似度可以取代布尔向量的jaccard吗，我们可以验证一下</p>
<p>如下图所示，第1行为原输入矩阵的Jaccard相似度，第2行为通过MiniHash降维后得到的Signature Metrix的Jaccard相似度。可以看出降维前后的相似度差距不是很大，但是两者之间的计算时间+空间量级得到了大大压缩。精度换时间，何乐而不为~<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154240.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154240.png" alt="image.png" style="max-width: 100%;"></a></p>
<h2>LSH</h2>
<p>假设有很多文本经过了前两步得到了一个很大的哈希签名矩阵，矩阵的每个列代表原来的一段文本。</p>
<p>需要将这个矩阵分成b组（b个bands），每一组有r行，且每一个band拥有独立的桶空间。<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154308.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154308.png" alt="image.png" style="max-width: 100%;"></a></p>
<p>然后对每一组的所有列分别进行hash，映射到不同的桶中。对于两个列，只要任意一组能够hash到同一个桶中，那么这两个列就可以成为相似项<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154325.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154325.png" alt="image.png" style="max-width: 100%;"></a><br>
<strong>举一个简单的例子</strong></p>
<p>有两个文章，文章 A和文章B</p>
<p>设置哈希签名的维数num_perm=128，经过前两个步骤后，可以得到各自的minHash签名：</p>
<ul>
<li>
<p>文章 A 的签名： [5, 7, 3, 9, ..., 42]（128个数字）</p>
</li>
<li>
<p>文章 B 的签名： [5, 7, 4, 9, ..., 43]（128个数字）</p>
</li>
</ul>
<p>接下来进行LSH，设band=32，则每个band中有4个值</p>
<p>文章A的签名 [5, 7, 3, 9, ..., 42] 分段：Band 1：[5, 7, 3, 9]（前 4 位）... Band 32：[最后 4 位，比如 39, 41, 43, 42]</p>
<p>文章B的签名 [5, 7, 4, 9, ..., 43] 分段：Band 1：[5, 7, 4, 9]（前 4 位）... Band 32：[最后 4 位，比如 39, 41, 42, 43]</p>
<p>每个Band有不同的桶空间：</p>
<p>对于第一个桶空间（Band1），对A的Band1进行哈希（此处的哈希函数简单设为各数相加）得到24，对B的Band1进行哈希得到25，设桶的个数100，A的Band1在桶24中，B的Band1在桶25中，不在一个桶</p>
<p>...</p>
<p>对于第三十二个桶空间（Band32），对A的Band32进行哈希（此处的哈希函数简单设为各数相加）得到165，对B的Band1进行哈希得到165，设桶的个数100，A的Band1在桶65中，B的Band1在桶65中，在一个桶</p>
<p>因此A和B是相似候选对</p>
<h2>对LSH的理解</h2>
<p>MinHash-LSH的第三步LSH的目的就是减少要与查询向量（实际上是哈希签名）进行jaccard相似度计算的向量总数（实际上是哈希签名）。</p>
<p>如下图所示，假设现在向量数据库中已经存储了100万个向量（哈希签名），如果不使用LSH，需要对一个查询向量计算100万次jaccard相似度，如果使用LSH：假设一个哈希签名有32个band，不同band拥有独立的桶空间，每个band有10万个桶，（平均一个桶中映射10个向量），则总共有320万个桶。此时，对一个查询向量的32个band各自会映射到一个桶中，平均可以取到320个向量（实际情况远低于320，因为每个band对应的桶中的向量id存在大量重复的），此时就只需要计算320次jaccard相似度。<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154417.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20251218154417.png" alt="image.png" style="max-width: 100%;"></a></p>
<h2>使用MinHash-LSH进行向量检索总结</h2>
<p>在通过上述过程构建了完整的LSH之后，对于一个要查询的向量，首先会计算其哈希签名，然后得到所在多个桶（每个band各一个）的id，然后就可以获取所有候选向量的哈希签名，之后就是计算该查询向量的哈希签名与所有候选向量的哈希签名的<strong>Jaccard相似度</strong>，最终排序得到top-K返回结果。</p>
<h1>算法适用场景与局限性</h1>
<p><strong>适用场景</strong></p>
<p>MinHash-LSH 是为<strong>集合 / 布尔向量</strong>和<strong>Jaccard 相似度度量</strong>设计的检索技术，在向量数据库中主要适配以下场景：</p>
<ul>
<li>文档/数据去重：MinHash-LSH在向量数据库中的存储是基于<strong>词袋</strong>的，可以快速识别表明意思重复或冗余的文档</li>
<li>粗筛预处理：在语义检索场景中，MinHash-LSH可作为前置粗筛模块，先通过词汇重叠度筛选出与查询文本词汇相关的候选向量，再将候选集送入 HNSW、IVF 等适配语义 embedding 的 ANNS 索引做精准检索，大幅缩小后续检索范围</li>
</ul>
<p><strong>局限性</strong></p>
<ul>
<li><strong>仅适配 Jaccard 相似度，不兼容语义检索</strong>：无法处理基于余弦 / 欧式距离的语义 embedding 向量。对于 “同义不同词” 的语义关联（如 “新能源车” 和 “电动汽车”），因其词汇集合重叠度低，会被判定为不相似，无法满足语义检索需求。如果想作为前置粗筛模块，后续与embedding索引结合，则向量数据库通常需要存储两套向量表示</li>
<li><strong>不适配稠密实数向量的直接检索</strong>：对语义 embedding 这类稠密实数向量，需先将其转化为集合 / 布尔向量才能处理，该转化过程会丢失语义信息，导致后续检索失去语义关联性，因此无法作为稠密向量的核心检索算法</li>
</ul></div>
<div style="font-size:small;margin-top:8px;float:right;"></div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://waibibab-cs.github.io">waibibab's blog</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","waibibab-cs/waibibab-cs.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>


</html>
