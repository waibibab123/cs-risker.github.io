<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://avatars.githubusercontent.com/u/105782835?s=400&u=04c0291bd1e06b01ccad1d53388ed4a8a8894a53&v=4"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="论文全名：Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures
# 摘要
部署在边缘设备上的大型语言模型（LLMs）通过微调并更新其部分参数进行学习。">
<meta property="og:title" content="【论文阅读;ICCAD'24】RoCR：基于边缘计算存算一体架构的RAG鲁棒实现">
<meta property="og:description" content="论文全名：Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures
# 摘要
部署在边缘设备上的大型语言模型（LLMs）通过微调并更新其部分参数进行学习。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://waibibab-cs.github.io/post/%E3%80%90-lun-wen-yue-du-%3BICCAD%2724%E3%80%91RoCR%EF%BC%9A-ji-yu-bian-yuan-ji-suan-cun-suan-yi-ti-jia-gou-de-RAG-lu-bang-shi-xian.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/105782835?s=400&u=04c0291bd1e06b01ccad1d53388ed4a8a8894a53&v=4">
<title>【论文阅读;ICCAD'24】RoCR：基于边缘计算存算一体架构的RAG鲁棒实现</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>




<body>
    <div id="header">
<h1 class="postTitle">【论文阅读;ICCAD'24】RoCR：基于边缘计算存算一体架构的RAG鲁棒实现</h1>
<div class="title-right">
    <a href="https://waibibab-cs.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/waibibab-cs/waibibab-cs.github.io/issues/12" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><p>论文全名：Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures</p>
<h1>摘要</h1>
<p>部署在边缘设备上的大型语言模型（LLMs）通过微调并更新其部分参数进行学习。尽管这类学习方法可通过优化降低资源占用，但整体所需资源对边缘设备而言仍构成沉重负担。相比之下，检索增强生成（RAG）作为一种资源高效型 LLM 学习方法，无需更新模型参数即可提升 LLM 生成内容的质量。然而，基于 RAG 的 LLM 在每次用户与模型的交互过程中，可能需要对用户文档数据进行重复检索。这种检索操作会随着用户数据的累积产生显著延迟。传统的延迟优化方案往往通过限制存储的用户数据量来实现，这导致 RAG 在用户数据持续增长的场景下，可扩展性大幅下降。一个亟待解决的问题是：如何让边缘设备上的 RAG 摆脱延迟与可扩展性的双重约束？<br>
本文提出一种基于内存计算（CiM）架构的新型框架，用于加速 RAG 的运行。该框架通过在内存内部执行原位计算，避免了计算单元与内存之间高昂的数据传输开销，从而高效加速矩阵乘法运算。我们提出的鲁棒性内存计算驱动型 RAG 框架（RoCR），融合了创新的对比学习训练方法与噪声感知训练机制，能够使 RAG 借助 CiM 架构实现对文档数据的高效检索。据我们所知，这是首个将 CiM 用于 RAG 加速的研究工作。</p>
<h1>背景介绍</h1>
<p>新兴的大型语言模型（LLMs）主要部署在中心化云平台上 （即云端大语言模型，Cloud LLM），这引发了用户对隐私与可信度的担忧，在医疗 、陪伴型助手 、个人助理等领域，这些问题尤为突出。为解决这些问题，云端大语言模型最终将向个性化大语言模型转型：即部署在边缘设备上的 “边缘大语言模型（Edge LLM）”，用户可在本地留存所有隐私数据，模型也能从本地数据中学习。</p>
<p>为更好地适配个体用户的需求，边缘大语言模型需从用户交互中学习。然而，其学习能力受限于边缘设备有限的内存（RAM）与计算能力。与云端大语言模型类似，边缘大语言模型主要通过微调自身参数进行学习。但这类模型通常包含超 30 亿个参数，即便投入大量优化精力，参数更新仍极具挑战。例如，在 NVIDIA AGX 这类实验性高性能嵌入式系统上，“口袋引擎法”仅从包含 5.2 万份文档的中型数据集 Alpaca 中学习，就需要 90 小时。<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108101847.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108101847.png" alt="image.png" style="max-width: 100%;"></a><br>
检索增强生成（RAG）是一种资源效率更高的方案。典型的 RAG 系统由检索器与生成器组成：检索器通常基于最大内积搜索（MIPS）实现。当检索器接收到用户查询时，会从文档数据中检索最相关的文档（如图 1 所示）。文档数据包含大量文档，每个文档di​都包含特定信息；生成器本质是一个大语言模型，它以用户查询x与检索器获取的文档为提示词，生成对应的响应。</p>
<p>对于文档数据中的每个文档d与用户查询x，RAG 会利用图 1 所示的句子嵌入模型，将它们转换为向量（即分别表示为E(d)与E(x)）。文档对应的向量称为 “文档嵌入”，会以矩阵形式存储（如图 1 所示）；用户查询对应的向量称为 “查询嵌入”E(x)，将用于 MIPS 计算 —— 与所有文档嵌入执行内积运算P(x,di​)，内积值越大，用户查询与该文档的语义相似度越高。</p>
<p>尽管 RAG 的计算成本更适配边缘设备，但仍存在两个问题阻碍其在边缘大语言模型上的实时部署。首先，存储的文档数据一旦超过内存（RAM）容量，就需卸载到硬盘（HDD）或固态硬盘（SSD）等存储介质中。从 HDD 或 SSD 读取数据会显著增加数据传输延迟，导致实时用户交互难以实现。其次，RAG 的核心检索方法（MIPS）会随文档数据量增长而效率下降，在处理超大规模数据集时甚至可能变得难以承受。例如，在树莓派4B上，从 2100 万份文档中检索一条匹配的文档数据，MIPS 需要耗时 5 分钟—— 这甚至长于边缘大语言模型 2 分钟的推理时间。遗憾的是，目前针对边缘大语言模型优化 RAG 的研究寥寥无几。</p>
<p>为此，我们提出利用内存计算（CiM）架构来解决这一问题。如图 1 所示，基于内存阵列的 CiM 架构在加速矩阵 - 向量乘法（MIPS 的核心操作）方面展现出巨大潜力。CiM 架构通常借助大规模并行处理，直接在数据存储的内存阵列内执行计算，通过原位数据访问减少数据迁移，从而显著提升吞吐量。对于相同数量的文档，CiM 可在 50 毫秒内完成计算—— 这与普通边缘设备的计算延迟相比可忽略不计。此外，通过集成非易失性内存（NVM）器件（如相变存储器 PCM、阻变存储器 RRAM、铁电场效应晶体管 FeFET），CiM 在能效方面的表现远超传统基于 MOSFET 的设计。</p>
<p>遗憾的是，仅更换底层硬件并不足以解决问题 ——CiM 阵列中非易失性内存（NVM）器件的非理想特性会严重劣化 RAG 的性能。首先，CiM 架构中的运算易受多种噪声源影响，包括电子噪声（热噪声、散粒噪声和闪烁噪声）、器件间差异，以及来自辅助电路的线路噪声 。此类噪声问题在 RAG 应用中至关重要，因为生成内容的准确性和质量高度依赖底层计算的精度。此外，CiM 架构的设计初衷及优化目标主要是低分辨率计算；而且 CiM 阵列的尺寸通常固定（例如 64×64 ），与文档嵌入维度（如 128 维）并不匹配。因此，RAG 的数据精度（通常为 32 位浮点数 FP32）及其嵌入维度均需调整，以适配 CiM 交叉阵列的规格。</p>
<h1>相关工作</h1>
<h2>存内计算架构及非易失性内存</h2>
<p>如图1的中间部分所示，内存阵列是向量 - 矩阵乘法的核心组件。在该阵列中，矩阵值存储于非易失性内存（NVM）单元中 —— 这类单元采用 PCM、RRAM、FeFET 等新兴 NVM 技术，位于阵列横竖线的交叉点处。同时，向量值沿阵列的水平线传输。内存阵列内的运算通过直接利用物理定律，在模拟域中完成；但移位相加等多位乘法、排序等基础功能，需在数字域中实现。</p>
<p>CiM 阵列会受到多种变异与噪声的影响，其中最主要的两类是空间变异与时间变异：空间变异源于制造缺陷，同时存在局部与全局相关性；FeFET器件还会受时间变异影响 —— 内存开关的随机性会导致不同时间编程时，器件电导出现波动。时间变异通常在器件间相互独立，且与待编程的值无关。在本研究中，作为概念验证，我们聚焦于时间变异对深度神经网络（DNN）性能的影响：时间变异会使器件的编程电阻偏离预期值。所提出的框架也可通过调整，适配其他类型的变异源。</p>
<p>测量结果表明，器件变异导致的 DNN 权重噪声，可建模为零均值高斯噪声，且每个噪声对应一个与权重值相关的标准差。其详细表达式为：<br>
$v=v0​+Δv, Δv∼N(0,σv​)$<br>
其中，v是部署在加速器上的实际嵌入向量，v0​是目标嵌入向量，σv​是实验中测得的标准差。我们收集了 RRAM 与 FeFET 器件的测量结果，具体数值将在后续讨论。</p>
<h2>现有噪声消减方法</h2>
<p>目前已有多种策略用于解决 CiM 加速器中的器件变异问题，这些方法可分为<strong>软件类技术</strong>与<strong>硬件类技术</strong>两类。</p>
<p>软件类技术通常通过算法手段获得更鲁棒的深度神经网络（DNN）模型，或重新开发系统 —— 这类方法并不适用于生成更鲁棒的最大内积搜索（MIPS）解决方案。</p>
<p>在硬件类技术中，<strong>写验证流程</strong>是编程阶段最常用的方法之一：首先通过指定的脉冲模式将 NVM 器件编程至某一状态；随后验证器件的实际值，确认其电导是否处于目标值的规定范围内；若存在偏差，则触发补充更新脉冲，重置器件电导以接近目标值。这一循环会持续进行，直到编程值与目标值的偏差缩小至可接受范围，通常仅需数轮循环即可完成。前沿研究表明，通过选择性地对关键器件应用写验证，可在 DNN 中维持电路设计所要求的平均精度；此外，已有多种电路设计方案被提出，用于抵消各类器件变异的影响。</p>
<h1>RoCR设计</h1>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108110027.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108110027.png" alt="image.png" style="max-width: 100%;"></a><br>
如图 3 所示，本文提出的鲁棒性内存计算驱动型 RAG 框架（RoCR）包含三个部分：首先，通过对比学习利用训练数据优化训练模块；为了实现上述训练，我们需要基于文档数据构建对比训练数据对，并将其输入灵活的噪声感知训练模块；最后，通过性能分析获取 CiM 中非易失性内存（NVM）的约束条件，将这些约束编码到灵活的噪声感知训练模块中，用于训练句子嵌入模型 —— 最终使该模型生成的嵌入向量能够抵御目标 NVM 器件的变异影响，训练完成后，训练模块可转化为新的句子嵌入模型，生成适配 CiM 架构的嵌入向量。</p>
<h2>对比学习：三元组损失函数</h2>
<p>在基于 CiM 部署 RAG 时，首先需将嵌入向量存储到 NVM 中（如图 1 所示）。这些嵌入向量由句子嵌入模型生成，是文档数据的数值表征 —— 文档数据中的每个文档对应一个向量，存储在 NVM 上的嵌入向量会组成如图 1 中橙色块所示的矩阵。当用户查询被转换为嵌入向量后，CiM 可通过向量 - 矩阵乘法，同时对该用户查询嵌入与所有文档嵌入执行 MIPS 运算；内积结果中排名靠前的值将作为索引，用于检索对应的文档数据（如图 1 中粉色块所示），而检索到的用户相关文档即为 MIPS 的输出结果。<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108110933.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108110933.png" alt="image.png" style="max-width: 100%;"></a><br>
然而，正如 2.1 节所述，将文档嵌入写入 NVM 会使其受时间变异（器件变异）的影响，导致 NVM 中存储的嵌入向量与句子嵌入模型生成的原始嵌入向量存在差异。如图 4 的左边所示，基础嵌入模型生成的目标嵌入向量会在器件变异下偏离为含噪声的嵌入向量，使得不相关的嵌入向量因内积值更大，排名超过目标嵌入向量。</p>
<p>对比学习可通过 “推开不相似样本、拉近相似样本” 来学习表征，具体而言，对比损失函数可用于增大不相似样本间的距离。</p>
<p>我们的对比学习损失函数基于 Weinberger 等人的研究成果。对于小批量中包含的 N 个锚点样本xi​，我们的数据构造方法会为每个xi​构建 K 个正样本和 K 个负样本。由此得到样本集合${{(x_i, x_i^-, x_i^+)<em>k}</em>{i=1,...,N}}_{k=1,...,K}$​，其中xi−​和xi+​分别是对应xi​的负样本与正样本，且xi​与xi+​的相似度高于其与xi−​的相似度。此外，emb(xi​)表示xi​经模型学习得到的嵌入向量。此时，损失函数L的定义为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108112300.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108112300.png" alt="image.png" style="max-width: 100%;"></a><br>
距离d(xa​,xb​)是通过两个数据的嵌入向量emb(xa​)与emb(xb​)之间的欧氏距离计算得到的。而函数sim()的作用是计算语义相似度。m是一个超参数，目的是让正样本对更近、负样本对更远，但如果设的太大，就会导致训练困难、容易过拟合。</p>
<h2>数据构造</h2>
<p>要通过对比学习训练句子嵌入模型，构建正例与负例区分度明确的样本对至关重要。在本研究中，由于我们采用的是三元组对比损失而非样本对损失，因此会构建包含锚点样本、正例样本与负例样本的三元组样本。我们利用文档数据来构建这类三元组样本，而文档数据是在用户与大语言模型的交互过程中生成的，其中包含用户偏好信息。这类数据存在两种情况：一是文档数据可能包含显式标签，用于标识用户对对应内容的偏好响应；二是文档数据也可能是仅包含用户相关信息但无显式用户偏好的语句。如图 5 所示，为应对这两种情况，我们提出了两种数据构建方法：带显式标签的数据构建法（CDE）与带隐式标签的数据构建法（CDI）。<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108115558.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108115558.png" alt="image.png" style="max-width: 100%;"></a></p>
<h3>基于带显示标签的数据构建三元组（CDE）</h3>
<p>对于含显式标签的数据，每条数据包含文本内容c及其对应的标签l（该标签标识用户对内容c的偏好响应）。如图 5 的 CDE 部分所示，虚线框出的内容即为显式标签。我们会将这类数据构建为{(xi​,xi−​,xi+​)}格式的对比三元组样本。</p>
<p>假设文档数据集中包含n个文档，每条数据由内容ci​和对应标签li​组成（其中i∈{1,2,...,n}）。锚点样本xi​的构建方式为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108120406.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108120406.png" alt="image.png" style="max-width: 100%;"></a><br>
其中⊕表示拼接操作，此处专门用于将标签与内容组合。负例样本xi−​的构建方式为：将内容ci​与一个不同于li​的随机标签lj​拼接，具体如下：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108120439.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108120439.png" alt="image.png" style="max-width: 100%;"></a><br>
为负例随机分配不同标签，既能保证负例的多样性，又能保留与锚点样本一致的内容。</p>
<p>与构建锚点及负例不同，构建锚点对应的正例样本具有一定挑战性 —— 因为形式化语义相似的数据，比形式化语义不相似的数据更困难。为构建正例样本，我们遵循 SimCSE 方法 ，向句子嵌入模型M中加入丢弃率r。正例样本的构建过程包含两个主要步骤：<br>
首先，文本正例样本的形式化为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108120701.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108120701.png" alt="image.png" style="max-width: 100%;"></a><br>
此步骤将每个锚点与对应的正例对齐，实际上是将锚点数据复制一份，作为生成嵌入向量的起点。<br>
然后，嵌入向量的生成过程会根据嵌入模型M中应用的丢弃率而变化。当使用模型M生成锚点与负例的嵌入向量时，丢弃率被设为 0；与之相反，生成正例的嵌入向量时，会启用丢弃率r。因此，锚点、负例、正例的嵌入向量（如图 5 所示）可构建为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121026.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121026.png" alt="image.png" style="max-width: 100%;"></a><br>
r≠0的设置会使嵌入向量产生变异，从而增强模型识别 “语义相似但内容表达有变化” 数据的能力。</p>
<p>给定构建因子K，我们可将三元组数据样本构建为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121258.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121258.png" alt="image.png" style="max-width: 100%;"></a><br>
对于三元组数据样本Dtriplet​，其对应每个增强版本k的嵌入向量为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121525.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121525.png" alt="image.png" style="max-width: 100%;"></a></p>
<p>总之，对于含显式标签的数据：可将内容c与其对应标签l拼接以构建锚点样本；将内容c与其他标签l′拼接以构建负例样本；正例样本最终由启用了丢弃率r的句子嵌入模型生成；而锚点与负例样本则由r=0的句子嵌入模型生成。</p>
<h2>基于带隐式标签的数据构建三元组（CDI）</h2>
<p>对于含隐式标签的数据，每条数据仅包含文本内容c（如图 5 的 CDI 部分所示），不存在标识用户偏好的显式标签，这类数据可被视为包含用户相关信息的语句。</p>
<p>在构建锚点样本与正例样本时，我们可采用与 CDE 完全相同的方法。假设文档数据集D包含n条数据，每条数据由内容ci​组成，则锚点样本xi​的构建方式为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121839.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121839.png" alt="image.png" style="max-width: 100%;"></a><br>
对于每个锚点数据xi​，构建其对应的负例样本并不像 “将内容ci​与不匹配的标签lk​拼接” 那样简单。因此，我们采用与正例样本相似的方法来构建负例样本，即通过模型方法实现。<br>
首先，我们按照公式 5 初始化负例样本与正例样本：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121929.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108121929.png" alt="image.png" style="max-width: 100%;"></a><br>
对于正例样本xi+​，可通过在句子嵌入模型M中加入丢弃率r（0&lt;r≤0.2）来最终确定。这一操作能生成与xi​语义表征相似的嵌入向量，同时保证良好的模型训练性能。若将丢弃率调至更高值（如 0.5），会扭曲xi+​的语义表征，使其与xi​的语义相似度降低。用这类正例样本训练模型，会导致模型性能下降 —— 对句子嵌入模型而言，过高的丢弃率更像是噪声，而非数据增强手段。</p>
<p>在本研究中，我们训练句子嵌入模型，使其生成的嵌入向量在噪声环境下（如在内存计算（CiM）中）仍能保持完整性。这类噪声会将原始语义表征打乱，例如，如图 5 所示，使用较高的丢弃率r=0.9可生成表征受损的负例样本。尽管这类负例样本可能缺失部分区分性内容，但它与锚点样本和正例样本存在明确差异，能有效模拟 CiM 的干扰效果。该方法不仅能在语义上区分负例样本，还能使其适配噪声感知训练所需的受损数据场景。</p>
<p>对于公式 9 所示的噪声三元组样本(xi​,xi−​,xi+​)（i=1,2,...,n），我们使用丢弃率r（0&lt;r≤0.2）构建正例样本；相应地，构建负例样本的丢弃率为1−r。<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122057.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122057.png" alt="image.png" style="max-width: 100%;"></a></p>
<h2>灵活的噪声感知训练</h2>
<p>在前两个阶段中，我们已基于对比学习构建了用于训练句子嵌入模型的数据。同时，通过注入模拟的器件变异，能让训练更有效，从而使模型针对这类变异实现优化。此外，句子嵌入模型需要生成适配不同 CiM 的嵌入向量（不同 CiM 可能采用不同的 NVM 设计），因此需要让模型调整其输出嵌入向量的维度与精度。为此，我们提出了一种<strong>灵活的噪声感知训练方法</strong>，以生成兼具抗噪声能力、且适配各类 CiM 的嵌入向量。</p>
<p>如图 3 所示，在灵活的噪声感知训练模块中，句子嵌入模型生成的嵌入向量会依据 CiM 的 NVM 约束进行调整（要求维度为d、精度为p），同时注入器件变异以完成嵌入向量的形式化处理。图 3 中所示的 “调整模块” 可视为一个自编码器 ，用于重构输入的嵌入向量，其输入为锚点嵌入向量emb(xi​)，由维度d和精度p初始化，记为shp()，可表示为：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122414.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122414.png" alt="image.png" style="max-width: 100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122518.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122518.png" alt="image.png" style="max-width: 100%;"></a><br>
基于表2所示的器件变异，我们可得：<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122535.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108122535.png" alt="image.png" style="max-width: 100%;"></a><br>
其中$e'=emb(x_i)^{d*p}$。我们将器件变异作为噪声注入到嵌入向量中，得到形式化的$emb(x_i)^{d*p}$​；如图 3 所示，该嵌入向量会用于对比学习，以训练句子嵌入模型。</p>
<h1>实验评估</h1>
<h2>实验搭建</h2>
<h3>数据集</h3>
<p>我们采用了 5 个不同任务与领域的数据集，包括：引文识别 （Citation）、电影标签标注 （Movie）、产品评分（Rating）、新闻标题生成（News），以及 DBLP 引文网络 V14 （DBLP）。每个数据集均包含查询数据与文档数据：在评估过程中，文档数据用于构建用户历史信息，对应的查询数据则作为用户输入。<br>
前三个数据集分别对应二分类、五分类与十五分类任务；最后两个数据集包含文本生成任务：</p>
<ul>
<li>在 “引文识别” 数据集中，每条查询数据由论文标题和两篇参考文献组成，RAG 需利用文档数据中对应论文的详细内容，从这两篇文献中选择正确的参考文献；</li>
<li>在 “电影标签标注” 数据集中，每条查询数据包含电影描述，RAG 需利用文档数据中相似的电影描述及其对应标签，为查询数据标注标签；</li>
<li>“产品评分” 数据集的结构与 “电影标签标注” 数据集类似；</li>
<li>在 “新闻标题生成” 与 “DBLP” 数据集中，每条查询数据包含摘要内容，需将其总结为标题，RAG 需利用文档数据中相似的摘要及其对应标题，为查询数据生成标题。<br>
所有 5 个数据集的查询数据均包含标签。</li>
</ul>
<h3>实验配置</h3>
<p>我们的框架选择 all-MiniLM-L6-v2作为句子嵌入模型。对于每个数据集，从文档数据中随机选取 2000个文档作为锚点样本。为验证 CDE 的数据构建方法，我们将增强因子k设为 5，以获取 10000 个负例样本；同时将丢弃率设为 0.1 以生成正例样本，而在处理锚点与负例样本时，丢弃率设为 0。为验证 CDI 的数据构建方法，我们将正例样本的丢弃率设为 0.1，负例样本的丢弃率设为 0.9；为与 CDE 的实验保持一致，CDI 实验中同样将k设为 5，并对结果进行 5 次运行后取平均值。在实验中，我们将器件变异σ设为 0.1，同时将嵌入向量调整为维度 64、精度 int8 的形式；学习率设为2e−5。</p>
<p>在所有实验中，我们遵循前文所述的器件变异与模型设置。具体参数是从三种代表性 NVM 器件中抽象并简化得到的：其中两种是阻变随机存取存储器（RRAM）器件，另一种是铁电场效应晶体管（FeFET）器件。我们分别对RRAM1​、RRAM4​与FeFET2​进行了建模，同时外推建模数据得到了两种合成器件FeFET3​与FeFET6​。详细的器件建模结果展示于表 2 中。“x-level 器件” 表示该器件可表示x个不同的值；而$​σ_{L_2}=0.01$表示该器件在表示值 2 时的变异为 0.01。我们利用从真实 CiM 器件中得到的器件变异，在单台 Nvidia A10 GPU 上进行实验。文档嵌入会根据不同 CiM 器件的要求调整格式，并以并行阵列的形式存储，这与实际场景中嵌入向量映射至多组 NVM 器件的方式一致。例如，若某一嵌入向量被调整为全 uint8 值的形式，当它被映射到FeFET2​这类 4-level（2-bit）器件时，向量的每个元素会由 4 个器件来表示。</p>
<h3>评估方法</h3>
<p>我们使用<strong>准确率</strong>评估模型在不同类别下正确分类样本的能力，使用<strong>F1 分数</strong>评估分类任务中精确率与召回率的平衡情况。对于 Rating 数据集，我们既会验证其多分类能力，也会从回归的角度，使用 <strong>平均绝对误差（MAE）</strong> 与<strong>均方根误差（RMSE）</strong>  进行评估：</p>
<ul>
<li>MAE 衡量预测结果中误差的平均幅度，可直观评估模型预测评分值的整体准确性；</li>
<li>RMSE 是预测评分与实际评分之间平方差的平均值的平方根，对较大误差更敏感，能凸显模型预测结果与真实值之间的显著偏差。<br>
对于 News 和 DBLP 数据集，其标签为句子，这类数据集用于验证文本生成能力。我们使用<strong>ROUGE-1</strong>和<strong>ROUGE-L</strong>评估生成文本与参考文本之间的重叠度：ROUGE-1 捕捉单个词的精确率与召回率，ROUGE-L 捕捉最长匹配序列，以此全面评估文本生成质量。<br>
此外，我们使用<strong>准确率</strong>衡量最大内积搜索（MIPS）的性能（即 MIPS 准确率），其表示 “器件变异下的 MIPS 结果” 与 “无器件变异的 MIPS 结果（参考值）” 的匹配比例。</li>
</ul>
<blockquote>
<p>指标解释：<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108144840.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108144840.png" alt="image.png" style="max-width: 100%;"></a></p>
</blockquote>
<h3>基线</h3>
<p>由于这是首项针对边缘端 CiM 提升 RAG 鲁棒性的工作，目前暂无最先进的方法可供对比。因此，我们基于过往用于增强深度神经网络（DNN）鲁棒性的噪声缓解方法构建了基准方法：<br>
第一个基准方法是选择性写验证（SWV）。该方法原本利用二阶导数评估器件变异对神经网络权重的影响，我们则用二阶导数衡量 “真实嵌入向量” 与 “器件变异下的嵌入向量” 之间的偏差。<br>
第二个基准方法是 CxDNN。该方法原本通过补偿因子提升向量 - 矩阵乘法的鲁棒性，我们则用补偿因子校准受器件变异影响的嵌入向量。<br>
第三个基准方法是 CorrectNet ，它利用交叉熵损失与正则化来增强 CiM 中神经网络的鲁棒性。我们将其作为基准方法时，也采用交叉熵损失正则化作为损失函数，以校准器件输出的嵌入向量。<br>
此外，我们将未采用任何噪声缓解方法的 “vanilla RAG” 作为第四个基准方法。</p>
<h2>实验结果</h2>
<p>对于 RAG 而言，它可简化为 “MIPS（最大内积搜索）+ 大语言模型（LLM）” 的组合：MIPS 作为检索器搜索合适的信息，LLM 作为生成器处理检索结果。因此，在实验中，我们首先评估 device-1 的器件变异下 MIPS 的性能 —— 将无器件变异时得到的 MIPS 结果作为参考（即真实值），通过 MIPS 准确率这一指标，衡量器件变异下的 MIPS 结果与参考结果的匹配数量。由于检索内容的质量很大程度上取决于基础句子嵌入模型，而我们的研究<strong>重点是缓解器件变异对嵌入模型的影响</strong> ，因此未对参考结果的质量进行评估。</p>
<p>如表 3 所示，在五个数据集上，采用两种数据构建方法的我们的框架，性能均优于四个基准方法。这表明我们的框架能够缓解器件变异导致的嵌入向量扰动。这些结果也与图 2 中的初步研究结论一致：在朴素高斯噪声中，σ 的增大会损害 MIPS 的性能。<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108145420.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108145420.png" alt="image.png" style="max-width: 100%;"></a><br>
在对比了我们框架与各基准方法的 MIPS 性能后，我们进一步开展了全面评估，以展示它们的 RAG 整体性能。在 RAG 中，我们采用 Gemma-2B 作为大语言模型。此外，我们还基于 Gemma-2B 运行了无器件变异的 RAG，以观测其理想性能，测得 Citation 数据集的准确率为 0.5200、Movie 数据集的准确率为 0.3728、Rating 数据集的平均绝对误差为 0.3150、News 数据集的 ROUGE-1 值为 0.0855、DBLP 数据集的 ROUGE-1 值为 0.2295。</p>
<p>我们在五种 CiM 器件上对五个数据集的 RAG 性能进行了验证，这些器件的变异参数已在表 2 中列出。如表 1 所示，在相同数据集下，各类器件变异均会显著降低 RAG 的鲁棒性，而我们的框架能够有效缓解不同类型的器件变异带来的影响。例如，在 Device-2 上，Citation 数据集的 RAG 性能波动区间为 0.18 至 0.48，而我们的框架可将该数据集在所有五种器件上的准确率提升至 0.5 以上。相比之下，四个基准方法的性能均明显低于理想水平，而我们的框架通过生成更优质的句子嵌入向量，性能不仅显著逼近理想水平，部分场景下甚至实现了超越。这是因为我们提出的鲁棒性内存计算驱动型 RAG 框架（RoCR）同时具备正则化作用，可提升模型的泛化能力。</p>
<p>此外，我们还评估了不同大语言模型对框架性能的影响。如图 1 所示，大语言模型的输入为 MIPS 检索到的数据与用户查询语句的拼接结果，并据此生成针对用户查询的回复。由于面对相同查询时，不同大语言模型生成的回复可能存在差异，因此我们在实验中选取了四款当前主流的、适用于边缘端的中等规模大语言模型，以验证框架性能。其中，Gemma-2B 是谷歌推出的一款全新的最优开源模型，模型权重为 4.95G；据谷歌官方介绍，该模型的性能优于同类型模型。我们同时选取了 Meta 推出的首批开源大语言模型之一 ——Llama2-3B ，其模型权重为 6.85G；微软发布的 Phi-2 ，这是一款性能强大的小型大语言模型，权重为 5G；以及继 Llama 系列之后表现出色的 Mistral AI 模型 ——Mistral7B-GPTQ 。实验选取 Citation 和 Movie 两个数据集，采用默认实验配置，设置器件变异参数 σ=0.1，并以 CiM Device-1 为实验环境，结果如图 6 所示。可以清晰地看到，在五种 CiM 器件上，我们的框架性能均优于所有基准方法；此外，各基准方法在同一数据集上的性能会因器件不同而产生较大波动，而我们的框架则能够实现更稳定、更鲁棒的性能表现。<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108145707.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108145707.png" alt="image.png" style="max-width: 100%;"></a><br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108145922.png"><img src="https://raw.githubusercontent.com/waibibab-cs/blog_img/main/cdnimg/20260108145922.png" alt="image.png" style="max-width: 100%;"></a></p>
<h1>总结</h1>
<p>本文提出了一种基于存内计算（CiM）架构的检索增强生成（RAG）加速新框架。该方法为 RAG 突破边缘设备的延迟与可扩展性限制提供了一种解决方案。通过对句子嵌入模型进行优化，本框架能够利用 CiM 器件存储和处理文档嵌入向量，最大限度地降低 CiM 器件变异带来的影响。实验结果表明，该框架不仅实现了更优的 RAG 性能，还大幅缓解了器件变异造成的影响。本文是首个基于 CiM 架构实现 RAG 加速的研究成果。</p>
<p>该工作的重点是优化嵌入模型的抗pim期间噪声的能力，比如实验并没有测试使用pim的rag的时延相比其他rag工作优化多少，而是对比不同方案在噪声影响下的准确率等指标。</p></div>
<div style="font-size:small;margin-top:8px;float:right;"></div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://waibibab-cs.github.io">waibibab's blog</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","waibibab-cs/waibibab-cs.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>
<script>MathJax = {tex: {inlineMath: [["$", "$"]]}};</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</html>
